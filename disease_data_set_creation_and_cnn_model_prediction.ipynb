{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disease data set creation and cnn model prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTD3kRxUiqfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyzfNNAxiv5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxFdU1knjJq-",
        "colab_type": "code",
        "outputId": "fe526fa0-e3ad-44a7-da93-c2d6a630f8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ZUrP4088Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from numpy import expand_dims\n",
        "from scipy import ndimage\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    vertical_flip=True,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "\n",
        "atypical=[]\n",
        "for filename in glob.glob('./data/atypical/*.jpg'): \n",
        "    image =load_img(filename)\n",
        "    image=img_to_array(image)\n",
        "    image= expand_dims(image, 0)\n",
        "    atypical.append(image)\n",
        "\n",
        "save_here = './data/atypical/'\n",
        "for new_image in atypical:\n",
        "  datagen.fit(new_image)\n",
        "  for x, val in zip(datagen.flow(new_image,                    \n",
        "          save_to_dir=save_here,     \n",
        "          save_prefix='aug',        \n",
        "          save_format='jpg'),range(10)) :     \n",
        "    pass\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvoFae8taSrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corn=[]\n",
        "for filename in glob.glob('./data/corn/*.jpg'): \n",
        "    image =load_img(filename)\n",
        "    image=img_to_array(image)\n",
        "    image= expand_dims(image, 0)\n",
        "    corn.append(image)\n",
        "\n",
        "\n",
        "save_here = './data/corn/'\n",
        "for new_image in corn:\n",
        "  datagen.fit(new_image)\n",
        "  for x, val in zip(datagen.flow(new_image,                    \n",
        "          save_to_dir=save_here,     \n",
        "          save_prefix='aug',        \n",
        "          save_format='jpg'),range(10)) :  \n",
        "     \n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kQUQuITcwNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eyelid=[]\n",
        "for filename in glob.glob('./data/eyelid/*.jpg'): \n",
        "    image =load_img(filename)\n",
        "    image=img_to_array(image)\n",
        "    image= expand_dims(image, 0)\n",
        "    eyelid.append(image)\n",
        "\n",
        "\n",
        "save_here = './data/eyelid/'\n",
        "for new_image in eyelid:\n",
        "  datagen.fit(new_image)\n",
        "  for x, val in zip(datagen.flow(new_image,                    \n",
        "          save_to_dir=save_here,     \n",
        "          save_prefix='aug',        \n",
        "          save_format='jpg'),range(10)) :  \n",
        "     \n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ry53i71C1Sy",
        "colab_type": "text"
      },
      "source": [
        "#datagen\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5jOJPSa9Bwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkocdxraxnwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho4XiN2ajaKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en9u7Pi60yBR",
        "colab_type": "text"
      },
      "source": [
        "#**new**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frt3B_WN0ztG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZHAv2LgglIS",
        "colab_type": "text"
      },
      "source": [
        "#Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krY_JjzG00WJ",
        "colab_type": "code",
        "outputId": "b126176f-c065-4c8c-8e4b-193b4f3ffb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "\n",
        "file_list = []\n",
        "class_list = []\n",
        "\n",
        "DATADIR = \"data\"\n",
        "\n",
        "# All the categories you want your neural network to detect\n",
        "CATEGORIES = [\"acne\",\"atypical\",\"corn\",\"eyelid\"]\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "IMG_SIZE = 50\n",
        "\n",
        "# Checking or all images in the data folder\n",
        "for category in CATEGORIES :\n",
        "\tpath = os.path.join(DATADIR, category)\n",
        "\tfor img in os.listdir(path):\n",
        "\t\timg_array = cv2.imread(os.path.join(path, img))\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "\tfor category in CATEGORIES :\n",
        "\t\tpath = os.path.join(DATADIR, category)\n",
        "\t\tclass_num = CATEGORIES.index(category)\n",
        "\t\tfor img in os.listdir(path):\n",
        "\t\t\ttry :\n",
        "\t\t\t\timg_array = cv2.imread(os.path.join(path, img))\n",
        "\t\t\t\tnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "\t\t\t\ttraining_data.append([new_array, class_num])\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tpass\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "\n",
        "for features, label in training_data:\n",
        "\tX.append(features)\n",
        "\ty.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Creating the files containing all the information about your model\n",
        "pickle_out = open(\"X.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_in = open(\"X.pickle\", \"rb\")\n",
        "X = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a297f2f4c073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATADIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-aJjotEgw4k",
        "colab_type": "text"
      },
      "source": [
        "#Machine Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmnuOv401yLg",
        "colab_type": "code",
        "outputId": "0942cfce-407a-475c-aa65-550f9287d033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D,BatchNormalization\n",
        "import pickle\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Opening the files about data\n",
        "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0\n",
        "\n",
        "''''''\n",
        "#conv\n",
        "input_shape = X.shape[1:]\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])\n",
        "''''''\n",
        "'''# Building the model\n",
        "model = Sequential()\n",
        "\n",
        "# 3 convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), input_shape = X.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 2 hidden layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "# The output layer with 4 neurons, for 4 classes\n",
        "model.add(Dense(4))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "# Compiling the model using some basic parameters\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "\t\t\t\toptimizer=\"adam\",\n",
        "\t\t\t\tmetrics=[\"accuracy\"])'''\n",
        "\n",
        "# Training the model, with 40 iterations\n",
        "# validation_split corresponds to the percentage of images used for the validation phase compared to all the images\n",
        "history = model.fit(X, y, batch_size=20, epochs=100, validation_split=0.1)\n",
        "\n",
        "# Saving the model\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file :\n",
        "\tjson_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "model.save('CNN.model')\n",
        "\n",
        "# Printing a graph showing the accuracy changes during the training phase\n",
        "print(history.history.keys())\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 774 samples, validate on 87 samples\n",
            "Epoch 1/100\n",
            "774/774 [==============================] - 4s 5ms/sample - loss: 1.6866 - acc: 0.4690 - val_loss: 3.0670 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "774/774 [==============================] - 1s 729us/sample - loss: 0.9060 - acc: 0.6770 - val_loss: 4.3748 - val_acc: 0.3333\n",
            "Epoch 3/100\n",
            "774/774 [==============================] - 1s 695us/sample - loss: 0.7020 - acc: 0.7455 - val_loss: 5.7921 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "774/774 [==============================] - 0s 631us/sample - loss: 0.5739 - acc: 0.7894 - val_loss: 5.7960 - val_acc: 0.3333\n",
            "Epoch 5/100\n",
            "774/774 [==============================] - 0s 639us/sample - loss: 0.4100 - acc: 0.8682 - val_loss: 6.2438 - val_acc: 0.3333\n",
            "Epoch 6/100\n",
            "774/774 [==============================] - 1s 700us/sample - loss: 0.3202 - acc: 0.8889 - val_loss: 6.0527 - val_acc: 0.3333\n",
            "Epoch 7/100\n",
            "774/774 [==============================] - 1s 677us/sample - loss: 0.2800 - acc: 0.9096 - val_loss: 7.5053 - val_acc: 0.3333\n",
            "Epoch 8/100\n",
            "774/774 [==============================] - 1s 713us/sample - loss: 0.3153 - acc: 0.8915 - val_loss: 7.5982 - val_acc: 0.3333\n",
            "Epoch 9/100\n",
            "774/774 [==============================] - 1s 719us/sample - loss: 0.2063 - acc: 0.9315 - val_loss: 7.4431 - val_acc: 0.3333\n",
            "Epoch 10/100\n",
            "774/774 [==============================] - 1s 698us/sample - loss: 0.2261 - acc: 0.9225 - val_loss: 3.9753 - val_acc: 0.3563\n",
            "Epoch 11/100\n",
            "774/774 [==============================] - 1s 686us/sample - loss: 0.2196 - acc: 0.9173 - val_loss: 4.2578 - val_acc: 0.3563\n",
            "Epoch 12/100\n",
            "774/774 [==============================] - 1s 670us/sample - loss: 0.1762 - acc: 0.9432 - val_loss: 2.5547 - val_acc: 0.4713\n",
            "Epoch 13/100\n",
            "774/774 [==============================] - 0s 634us/sample - loss: 0.1475 - acc: 0.9444 - val_loss: 1.7524 - val_acc: 0.5172\n",
            "Epoch 14/100\n",
            "774/774 [==============================] - 1s 655us/sample - loss: 0.1391 - acc: 0.9548 - val_loss: 1.8483 - val_acc: 0.5287\n",
            "Epoch 15/100\n",
            "774/774 [==============================] - 1s 678us/sample - loss: 0.1387 - acc: 0.9444 - val_loss: 1.5239 - val_acc: 0.6322\n",
            "Epoch 16/100\n",
            "774/774 [==============================] - 1s 688us/sample - loss: 0.1774 - acc: 0.9393 - val_loss: 1.7968 - val_acc: 0.6207\n",
            "Epoch 17/100\n",
            "774/774 [==============================] - 0s 626us/sample - loss: 0.1140 - acc: 0.9638 - val_loss: 0.6159 - val_acc: 0.7471\n",
            "Epoch 18/100\n",
            "774/774 [==============================] - 1s 661us/sample - loss: 0.2040 - acc: 0.9354 - val_loss: 3.2065 - val_acc: 0.8276\n",
            "Epoch 19/100\n",
            "774/774 [==============================] - 0s 628us/sample - loss: 0.1704 - acc: 0.9393 - val_loss: 0.3079 - val_acc: 0.8851\n",
            "Epoch 20/100\n",
            "774/774 [==============================] - 1s 694us/sample - loss: 0.1655 - acc: 0.9457 - val_loss: 0.3276 - val_acc: 0.8851\n",
            "Epoch 21/100\n",
            "774/774 [==============================] - 1s 669us/sample - loss: 0.0929 - acc: 0.9677 - val_loss: 0.1851 - val_acc: 0.9195\n",
            "Epoch 22/100\n",
            "774/774 [==============================] - 1s 714us/sample - loss: 0.0611 - acc: 0.9819 - val_loss: 0.2821 - val_acc: 0.9195\n",
            "Epoch 23/100\n",
            "774/774 [==============================] - 1s 652us/sample - loss: 0.0742 - acc: 0.9716 - val_loss: 0.1149 - val_acc: 0.9655\n",
            "Epoch 24/100\n",
            "774/774 [==============================] - 1s 693us/sample - loss: 0.0797 - acc: 0.9703 - val_loss: 0.4364 - val_acc: 0.9310\n",
            "Epoch 25/100\n",
            "774/774 [==============================] - 1s 648us/sample - loss: 0.0807 - acc: 0.9767 - val_loss: 1.4268 - val_acc: 0.8046\n",
            "Epoch 26/100\n",
            "774/774 [==============================] - 1s 696us/sample - loss: 0.0721 - acc: 0.9793 - val_loss: 1.0344 - val_acc: 0.8621\n",
            "Epoch 27/100\n",
            "774/774 [==============================] - 1s 670us/sample - loss: 0.0635 - acc: 0.9780 - val_loss: 0.3925 - val_acc: 0.8851\n",
            "Epoch 28/100\n",
            "774/774 [==============================] - 1s 660us/sample - loss: 0.0527 - acc: 0.9871 - val_loss: 1.0201 - val_acc: 0.8736\n",
            "Epoch 29/100\n",
            "774/774 [==============================] - 1s 687us/sample - loss: 0.0504 - acc: 0.9845 - val_loss: 0.7165 - val_acc: 0.8506\n",
            "Epoch 30/100\n",
            "774/774 [==============================] - 1s 748us/sample - loss: 0.0829 - acc: 0.9742 - val_loss: 0.1242 - val_acc: 0.9080\n",
            "Epoch 31/100\n",
            "774/774 [==============================] - 1s 716us/sample - loss: 0.0601 - acc: 0.9793 - val_loss: 0.4819 - val_acc: 0.9080\n",
            "Epoch 32/100\n",
            "774/774 [==============================] - 1s 680us/sample - loss: 0.0552 - acc: 0.9845 - val_loss: 0.3657 - val_acc: 0.8966\n",
            "Epoch 33/100\n",
            "774/774 [==============================] - 0s 638us/sample - loss: 0.0535 - acc: 0.9832 - val_loss: 0.4526 - val_acc: 0.9195\n",
            "Epoch 34/100\n",
            "774/774 [==============================] - 0s 633us/sample - loss: 0.0817 - acc: 0.9703 - val_loss: 0.8283 - val_acc: 0.8851\n",
            "Epoch 35/100\n",
            "774/774 [==============================] - 1s 665us/sample - loss: 0.0819 - acc: 0.9729 - val_loss: 1.1172 - val_acc: 0.7701\n",
            "Epoch 36/100\n",
            "774/774 [==============================] - 1s 652us/sample - loss: 0.0932 - acc: 0.9677 - val_loss: 2.1877 - val_acc: 0.6667\n",
            "Epoch 37/100\n",
            "774/774 [==============================] - 1s 696us/sample - loss: 0.0947 - acc: 0.9716 - val_loss: 0.2117 - val_acc: 0.9425\n",
            "Epoch 38/100\n",
            "774/774 [==============================] - 1s 668us/sample - loss: 0.0943 - acc: 0.9651 - val_loss: 0.6073 - val_acc: 0.9195\n",
            "Epoch 39/100\n",
            "774/774 [==============================] - 0s 643us/sample - loss: 0.0752 - acc: 0.9716 - val_loss: 0.6164 - val_acc: 0.8621\n",
            "Epoch 40/100\n",
            "774/774 [==============================] - 1s 666us/sample - loss: 0.0582 - acc: 0.9767 - val_loss: 0.5259 - val_acc: 0.8966\n",
            "Epoch 41/100\n",
            "774/774 [==============================] - 1s 699us/sample - loss: 0.0378 - acc: 0.9910 - val_loss: 1.4536 - val_acc: 0.8391\n",
            "Epoch 42/100\n",
            "774/774 [==============================] - 1s 673us/sample - loss: 0.0462 - acc: 0.9858 - val_loss: 0.0625 - val_acc: 0.9655\n",
            "Epoch 43/100\n",
            "774/774 [==============================] - 1s 658us/sample - loss: 0.0253 - acc: 0.9948 - val_loss: 0.1371 - val_acc: 0.9540\n",
            "Epoch 44/100\n",
            "774/774 [==============================] - 1s 723us/sample - loss: 0.0406 - acc: 0.9897 - val_loss: 0.1064 - val_acc: 0.9655\n",
            "Epoch 45/100\n",
            "774/774 [==============================] - 1s 756us/sample - loss: 0.0331 - acc: 0.9897 - val_loss: 0.2040 - val_acc: 0.9540\n",
            "Epoch 46/100\n",
            "774/774 [==============================] - 1s 673us/sample - loss: 0.0321 - acc: 0.9871 - val_loss: 0.3185 - val_acc: 0.9080\n",
            "Epoch 47/100\n",
            "774/774 [==============================] - 1s 666us/sample - loss: 0.0352 - acc: 0.9858 - val_loss: 0.5297 - val_acc: 0.9080\n",
            "Epoch 48/100\n",
            "774/774 [==============================] - 1s 662us/sample - loss: 0.0455 - acc: 0.9819 - val_loss: 0.8938 - val_acc: 0.8046\n",
            "Epoch 49/100\n",
            "774/774 [==============================] - 0s 643us/sample - loss: 0.0449 - acc: 0.9858 - val_loss: 0.2084 - val_acc: 0.9310\n",
            "Epoch 50/100\n",
            "774/774 [==============================] - 0s 632us/sample - loss: 0.0237 - acc: 0.9922 - val_loss: 0.0732 - val_acc: 0.9425\n",
            "Epoch 51/100\n",
            "774/774 [==============================] - 1s 655us/sample - loss: 0.0318 - acc: 0.9871 - val_loss: 0.8809 - val_acc: 0.8736\n",
            "Epoch 52/100\n",
            "774/774 [==============================] - 1s 659us/sample - loss: 0.0263 - acc: 0.9884 - val_loss: 0.2245 - val_acc: 0.9425\n",
            "Epoch 53/100\n",
            "774/774 [==============================] - 1s 680us/sample - loss: 0.0221 - acc: 0.9935 - val_loss: 0.1643 - val_acc: 0.9425\n",
            "Epoch 54/100\n",
            "774/774 [==============================] - 0s 646us/sample - loss: 0.0403 - acc: 0.9897 - val_loss: 0.1153 - val_acc: 0.9655\n",
            "Epoch 55/100\n",
            "774/774 [==============================] - 1s 695us/sample - loss: 0.0401 - acc: 0.9884 - val_loss: 0.3481 - val_acc: 0.9195\n",
            "Epoch 56/100\n",
            "774/774 [==============================] - 1s 690us/sample - loss: 0.0237 - acc: 0.9897 - val_loss: 0.4299 - val_acc: 0.9425\n",
            "Epoch 57/100\n",
            "774/774 [==============================] - 1s 675us/sample - loss: 0.0504 - acc: 0.9819 - val_loss: 0.5639 - val_acc: 0.8736\n",
            "Epoch 58/100\n",
            "774/774 [==============================] - 0s 633us/sample - loss: 0.0449 - acc: 0.9819 - val_loss: 0.2524 - val_acc: 0.9425\n",
            "Epoch 59/100\n",
            "774/774 [==============================] - 1s 646us/sample - loss: 0.0397 - acc: 0.9884 - val_loss: 0.2563 - val_acc: 0.9425\n",
            "Epoch 60/100\n",
            "774/774 [==============================] - 0s 628us/sample - loss: 0.0156 - acc: 0.9922 - val_loss: 0.1324 - val_acc: 0.9540\n",
            "Epoch 61/100\n",
            "774/774 [==============================] - 1s 658us/sample - loss: 0.0196 - acc: 0.9935 - val_loss: 0.3024 - val_acc: 0.9310\n",
            "Epoch 62/100\n",
            "774/774 [==============================] - 1s 745us/sample - loss: 0.0287 - acc: 0.9884 - val_loss: 0.2179 - val_acc: 0.9425\n",
            "Epoch 63/100\n",
            "774/774 [==============================] - 0s 631us/sample - loss: 0.0224 - acc: 0.9948 - val_loss: 0.2244 - val_acc: 0.9080\n",
            "Epoch 64/100\n",
            "774/774 [==============================] - 1s 696us/sample - loss: 0.0220 - acc: 0.9922 - val_loss: 0.2459 - val_acc: 0.8966\n",
            "Epoch 65/100\n",
            "774/774 [==============================] - 1s 664us/sample - loss: 0.0414 - acc: 0.9845 - val_loss: 0.3713 - val_acc: 0.8966\n",
            "Epoch 66/100\n",
            "774/774 [==============================] - 1s 678us/sample - loss: 0.1066 - acc: 0.9599 - val_loss: 1.2411 - val_acc: 0.7356\n",
            "Epoch 67/100\n",
            "774/774 [==============================] - 1s 657us/sample - loss: 0.0780 - acc: 0.9677 - val_loss: 0.3773 - val_acc: 0.8851\n",
            "Epoch 68/100\n",
            "774/774 [==============================] - 1s 716us/sample - loss: 0.0746 - acc: 0.9703 - val_loss: 0.7101 - val_acc: 0.8506\n",
            "Epoch 69/100\n",
            "774/774 [==============================] - 1s 680us/sample - loss: 0.0541 - acc: 0.9832 - val_loss: 0.1818 - val_acc: 0.9310\n",
            "Epoch 70/100\n",
            "774/774 [==============================] - 1s 713us/sample - loss: 0.0492 - acc: 0.9858 - val_loss: 0.3411 - val_acc: 0.9080\n",
            "Epoch 71/100\n",
            "774/774 [==============================] - 0s 634us/sample - loss: 0.0779 - acc: 0.9755 - val_loss: 0.2722 - val_acc: 0.9310\n",
            "Epoch 72/100\n",
            "774/774 [==============================] - 1s 699us/sample - loss: 0.0820 - acc: 0.9780 - val_loss: 0.2526 - val_acc: 0.9310\n",
            "Epoch 73/100\n",
            "774/774 [==============================] - 1s 647us/sample - loss: 0.0428 - acc: 0.9871 - val_loss: 0.2876 - val_acc: 0.9195\n",
            "Epoch 74/100\n",
            "774/774 [==============================] - 1s 663us/sample - loss: 0.0482 - acc: 0.9780 - val_loss: 0.3403 - val_acc: 0.8966\n",
            "Epoch 75/100\n",
            "774/774 [==============================] - 1s 667us/sample - loss: 0.0366 - acc: 0.9871 - val_loss: 0.2841 - val_acc: 0.9195\n",
            "Epoch 76/100\n",
            "774/774 [==============================] - 1s 664us/sample - loss: 0.0564 - acc: 0.9780 - val_loss: 0.1566 - val_acc: 0.9425\n",
            "Epoch 77/100\n",
            "774/774 [==============================] - 1s 689us/sample - loss: 0.0642 - acc: 0.9780 - val_loss: 0.3714 - val_acc: 0.9080\n",
            "Epoch 78/100\n",
            "774/774 [==============================] - 0s 637us/sample - loss: 0.0304 - acc: 0.9871 - val_loss: 0.3580 - val_acc: 0.8851\n",
            "Epoch 79/100\n",
            "774/774 [==============================] - 0s 645us/sample - loss: 0.0264 - acc: 0.9935 - val_loss: 0.5966 - val_acc: 0.9080\n",
            "Epoch 80/100\n",
            "774/774 [==============================] - 0s 641us/sample - loss: 0.0398 - acc: 0.9858 - val_loss: 0.6297 - val_acc: 0.8621\n",
            "Epoch 81/100\n",
            "774/774 [==============================] - 0s 638us/sample - loss: 0.0223 - acc: 0.9948 - val_loss: 0.2998 - val_acc: 0.9195\n",
            "Epoch 82/100\n",
            "774/774 [==============================] - 1s 703us/sample - loss: 0.0207 - acc: 0.9922 - val_loss: 0.1401 - val_acc: 0.9540\n",
            "Epoch 83/100\n",
            "774/774 [==============================] - 1s 702us/sample - loss: 0.0339 - acc: 0.9897 - val_loss: 0.1548 - val_acc: 0.9310\n",
            "Epoch 84/100\n",
            "774/774 [==============================] - 1s 667us/sample - loss: 0.0394 - acc: 0.9845 - val_loss: 0.2056 - val_acc: 0.9310\n",
            "Epoch 85/100\n",
            "774/774 [==============================] - 0s 627us/sample - loss: 0.0176 - acc: 0.9961 - val_loss: 0.1867 - val_acc: 0.9540\n",
            "Epoch 86/100\n",
            "774/774 [==============================] - 1s 656us/sample - loss: 0.0255 - acc: 0.9897 - val_loss: 0.2813 - val_acc: 0.9310\n",
            "Epoch 87/100\n",
            "774/774 [==============================] - 1s 648us/sample - loss: 0.0215 - acc: 0.9922 - val_loss: 0.2373 - val_acc: 0.9195\n",
            "Epoch 88/100\n",
            "774/774 [==============================] - 1s 663us/sample - loss: 0.0169 - acc: 0.9961 - val_loss: 0.1772 - val_acc: 0.9655\n",
            "Epoch 89/100\n",
            "774/774 [==============================] - 1s 695us/sample - loss: 0.0135 - acc: 0.9974 - val_loss: 0.2615 - val_acc: 0.9310\n",
            "Epoch 90/100\n",
            "774/774 [==============================] - 1s 686us/sample - loss: 0.0192 - acc: 0.9910 - val_loss: 0.2909 - val_acc: 0.9195\n",
            "Epoch 91/100\n",
            "774/774 [==============================] - 1s 668us/sample - loss: 0.0221 - acc: 0.9910 - val_loss: 0.4153 - val_acc: 0.9080\n",
            "Epoch 92/100\n",
            "774/774 [==============================] - 1s 700us/sample - loss: 0.0130 - acc: 0.9935 - val_loss: 0.5405 - val_acc: 0.9195\n",
            "Epoch 93/100\n",
            "774/774 [==============================] - 1s 743us/sample - loss: 0.0180 - acc: 0.9948 - val_loss: 0.1786 - val_acc: 0.9425\n",
            "Epoch 94/100\n",
            "774/774 [==============================] - 1s 709us/sample - loss: 0.0114 - acc: 0.9974 - val_loss: 0.2803 - val_acc: 0.9425\n",
            "Epoch 95/100\n",
            "774/774 [==============================] - 1s 674us/sample - loss: 0.0123 - acc: 0.9961 - val_loss: 0.2738 - val_acc: 0.9310\n",
            "Epoch 96/100\n",
            "774/774 [==============================] - 1s 670us/sample - loss: 0.0058 - acc: 0.9987 - val_loss: 0.2249 - val_acc: 0.9310\n",
            "Epoch 97/100\n",
            "774/774 [==============================] - 1s 688us/sample - loss: 0.0120 - acc: 0.9948 - val_loss: 0.1696 - val_acc: 0.9310\n",
            "Epoch 98/100\n",
            "774/774 [==============================] - 1s 695us/sample - loss: 0.0353 - acc: 0.9884 - val_loss: 0.3391 - val_acc: 0.9080\n",
            "Epoch 99/100\n",
            "774/774 [==============================] - 1s 657us/sample - loss: 0.0297 - acc: 0.9922 - val_loss: 0.4573 - val_acc: 0.9195\n",
            "Epoch 100/100\n",
            "774/774 [==============================] - 1s 692us/sample - loss: 0.0218 - acc: 0.9897 - val_loss: 1.0293 - val_acc: 0.8621\n",
            "Saved model to disk\n",
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f807e33e390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncyEwMyvcfwBSEOs2q0zI0QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8RsitR39R8p",
        "colab_type": "code",
        "outputId": "7b65119a-8dfd-437a-c6e6-e720bf145762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X.shape[1:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 50, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypNMyiTM637g",
        "colab_type": "code",
        "outputId": "25b0736e-5b75-45aa-dd9d-09ec3fe342aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 48, 48, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 46, 46, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 46, 46, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 21, 21, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 21, 21, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 19, 19, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 19, 19, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               5308928   \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 5,481,188\n",
            "Trainable params: 5,479,396\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s90lS2V1g_zF",
        "colab_type": "text"
      },
      "source": [
        "#testing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdrG3zDM2Iy-",
        "colab_type": "code",
        "outputId": "04d8f941-008e-4ce9-9c85-51cb589afb29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import tensorflow as tf \n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "model = tf.keras.models.load_model('CNN.model')\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "\t\t\t\toptimizer=\"adam\",\n",
        "\t\t\t\tmetrics=[\"accuracy\"])\n",
        "\n",
        "from keras.preprocessing import image\n",
        "import keras\n",
        "img = image.load_img('data/corno.jpg', target_size=(50, 50))\n",
        "#print(img)\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = model.predict_classes(images)\n",
        "print (classes)\n",
        "y_proba = model.predict(images)\n",
        "#y_classes = keras.np_utils.probas_to_classes(y_proba)\n",
        "print(y_proba)\n",
        "#print(y_classes)\n",
        "for pred in classes:\n",
        "\tprint(\"You have {} disease\".format(CATEGORIES[pred]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[[0. 1. 0. 0.]]\n",
            "You have atypical disease\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pEHFPNHHuiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}